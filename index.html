<html>
  <head>
    <title>Text Visualization</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    <link rel="stylesheet" href="assets/deck.css">
    <script src="vendor/jquery.min.js" type="text/javascript"></script>
  </head>
</html>
<body>
  <textarea id="source">
class:center,middle
# Text Analysis & Visualization
---
class:center,middle,inverse
# Text Analysis

---
# What is Text Data?
---
# What is Text Data?

![text data](assets/text_data_types.png)

(source: Chris Collins)
---
# What can I do with it?
---
# What can I do with it?

<br/><br/>

* Summarize a report or article
* Cluster and group a bunch of documents
* Understand and map cultural differences in language
* Understand how language changes over time
---
class:middle,center
# How?

# With Analysis & Visualization!
---
class:middle

# Motivating Examples
---

## Many Bills

![Many Bills](assets/many_bills.png)
<br>

> [by _Yannick Assogba, Irene Ros, et al_](http://clome.info/papers/manybills_chi.pdf)
---

## The Largest Vocabulary in Hip Hop

![The Largest Vocabulary in Hip Hop](assets/rapper-vocab.png)

> [by _Matt Daniels_](http://poly-graph.co/vocabulary.html)
---
class:center,middle,inverse
# Intro to Text Analysis

## (Enough to google search later)
---
# Analysis at Differet Angles
<br/><br/>

* Basic text data processing
* Finding interesting content in a document
* Comparing and clustering documents


---
class:center,middle
# Text As Data Processing

---
# Common Text Processing Procedures

# (Using [textkit](http://learntextvis.github.io/textkit/))


<br/>

`http://learntextvis.github.io/textkit/`

---
# Tokenization

```
pride.txt:

Mrs. Bennet deigned not to make any reply,
but, unable to contain herself,
began scolding one of her daughters.
```

`textkit text2words pride.txt`

```
Mrs.
Bennet
deigned
not
to
make
any
reply
,
ut
,
unable
to
contain
herself
,
began
scolding
one
of
her
daughters
.
```
---
# Not just for Single Words!

```
textkit text2ngrams pride.txt

Mrs. Bennet
Bennet deigned
deigned not
not to
to make
make any
any reply
reply ,
, but
but ,
, unable
unable to
to contain
contain herself
herself ,
, began
began scolding
scolding one
one of
of her
her daughters
daughters .
```
---
# Filtering and Transforming Tokens


## Punctuation Removal

```
textkit filterpunc tokens.txt
```

## Stop Word Removal

```
textkit filterwords tokens.txt
```

## Normalizing Case

```
texkit tokens2lower tokens.txt
```
---
# Stemming Word Tokens

```
tokens.txt:

houses
housed
house

textkit tokens2stem tokens.txt

hous
hous
hous

```
---
# Then what?

_want:_

# Text ⟿ Understanding

_get:_

# Text ⟿ Interesting Words

---
class:center,middle
# But what does _Interesting_ mean?
---
class:center,middle
# Finding Keywords
---
# Is it most frequent?

## Word frequency of _Alice in Wonderland_

```
textkit tokens2counts alice_tokens.txt

, 2418
the 1617
' 1127
. 975
and 810
to 720
a 620
she 544
it 539
of 499
said 462
! 450
alice 395
was 366
i 364
in 358
you 356
that 284
-- 264
```
---
## What about removing punctuation and stop words?

```
textkit tokens2counts alice_filtered.txt

said 462
alice 395
-- 264
little 128
one 99
would 90
know 87
could 86
like 85
went 83
queen 75
thought 74
time 68
see 67
king 62
began 58
turtle 58
hatter 56
mock 56
quite 55
gryphon 54
think 53
way 53
```

---
# Problem

Commonly used words in a language are not very informative.

What if we could find less common words used more frequently in a document?

---
# Problem

Commonly used words in a language are not very informative.

What if we could find less common words used more frequently in a document?

##Term Frequency - Inverse Document Frequency

That's the idea of TF-IDF!

But we use a large set of documents as a proxy for an entire language.
---
# TF-IDF

*TF* : Term Frequency : Number of times a word appears in a document.

*DF* : Document Frequency : Number of documents a word appears in.

Example:

>Doc 1 has turtle 3 times

>Doc 2 has turtle 0 times

>Doc 3 has turtle 12 times

Document Frequency is _2_.

*IDF* : Inverse Document Frequency : ` 1 / DF`

<br/>

So TF-IDF is:

```
TF * 1 / DF
```

---

TF-IDF is is just:

```
TF * 1 / DF
```

<br/>

but not really, typically there is a bit more work to it:

```
(TF / DL) * log(1 + N / document frequency)
```

Where `DL` is the Document Length of the document you are looking at.

And `N` is the number of documents total.

<br/><br/>

[Term Weighting for Humanists](https://porganized.com/2016/03/09/term-weighting-for-humanists/)

---

TF-IDF for _Alice in Wonderland_
```
[('alice', 0.4020951929645576),
 ('said', 0.12007273993951809),
 ('queen', 0.08817475297888497),
 ('turtle', 0.0842118811010307),
 ('hatter', 0.07992992104504608),
 ('mock', 0.07992992104504608),
 ('gryphon', 0.07707528100772301),
 ('duchess', 0.05994744078378456),
 ('dormouse', 0.05709280074646149),
 ('rabbit', 0.055256178533434584)]
```
---
class:center,middle
# Comparing Documents

---
# Comparing Documents

<br/><br/>

> Is Shakespeare more like E.L. James or L. Ron Hubbard?

> Which of these 1,000 documents are most like each other?

> Is this news article something that has been reported on before or something new?

---
# General Idea:

<br/><br/>

> Use the metrics calculated for a single document

> Combine for a lot of documents

> Represent in a big matrix

> Use geometry and vector math to compare
---
# Document Matrix

![doc matrix](assets/word_table.jpg)
---
# Each Row is a Vector

<br/><br/>

> Through `N` dimensional space, where `N` is the number of unique words in all documents.

# Cosine Similarity

> Can use to measure the angle between vectors and thus the similarity between them.
---
![vec space](assets/vector-space-2d-manning.png)
---

# Similarity Scores

Compare each Document with every other document.

```
[[ 1.          0.90245148  0.88100055  0.89342744  0.88611794]
 [ 0.90245148  1.          0.91397211  0.94348224  0.92777444]
 [ 0.88100055  0.91397211  1.          0.97169195  0.98256162]
 [ 0.89342744  0.94348224  0.97169195  1.          0.98316233]
 [ 0.88611794  0.92777444  0.98256162  0.98316233  1.        ]]
```
---
# Clustering

![k means](assets/k_mean_send.gif)
---
# What Else could be used as scores?

> TF-IDF !

> Remove Stop Words

> Part-of-Speech Weighting?
---
# POS Tagging

```
textkit tokens2counts tokens.txt

Mrs.,NNP
Bennet,NNP
deigned,VBD
not,RB
to,TO
make,VB
any,DT
reply,NN
",",","
but,CC
",",","
unable,JJ
to,TO
contain,VB
herself,PRP
",",","
began,VBD
scolding,VBG
one,CD
of,IN
her,PRP$
daughters,NNS
.,.

```
---

![](assets/syntaxnet.png)

> [Syntaxnet](http://googleresearch.blogspot.com/2016/05/announcing-syntaxnet-worlds-most.html?m=1)

> Parsey McParseface
---
class:middle,center
# Bonus Round

# Word Vectors
---
# Word2Vec

![](assets/word2vec-distributed-representation.png)

> [Amazing Power of Word Vectors](https://blog.acolyer.org/2016/04/21/the-amazing-power-of-word-vectors/)
---
![](assets/word2vec-king-queen-vectors.png)
---
![](assets/word2vec-king-queen-composition.png)
---
# Compare Different Languages!
![](assets/vector_space_model_multilingual1.png)

---
# `Vec` the world

![](assets/vecs.png)

> [awesome-2vec](https://github.com/MaxwellRebo/awesome-2vec)
---
class:middle,center

## learntextvis.github.io/textkit/

---
class:center,middle,inverse
# Text Visualization

## An Exploration of Visual Mappings

---
class:middle
# Size
---

<br/>
<br/>
![word cloud](assets/wordcloud.png)
[Wordclouds](https://www.jasondavies.com/wordcloud/#)

Classic Wordle
---

<br/>
<br/>
![bad word cloud](assets/bad_cloud.png)
[](http://www.theonion.com/graphic/most-used-words-in-the-gettysburg-address-34609)

Token's can also be multi-word tokens
---

<br/>
<br/>
![analytical word cloud](assets/comparison_cloud.png)

A more analytically oriented word cloud
---

<br/>
<br/>
![bubble cloud](assets/bubble.png)

[Bubble Cloud](http://www.nytimes.com/interactive/2012/09/06/us/politics/convention-word-counts.html)

[Bubble Cloud Tutorial](http://vallandingham.me/building_a_bubble_cloud.html)

---
class:middle
# Position
---

![text arc](assets/textarc.gif)

[TextArc](http://www.textarc.org/Stills.html)  /  [Interactive Version](http://vallandingham.me/textarc/)


---

![stereotropes](assets/stereotropes.png)

[Stereotropes](http://stereotropes.bocoup.com/)

---

![wordwanderer](assets/wordwanderer.png)

[WordWanderer](http://wordwanderer.org/)

---
class:middle
# Structure
---

<br/>
<br/>
<br/>
<br/>
![concordance](assets/concordance.png)
[Quick Concordance Plots](http://vallandingham.me/concordance_plot/)

---


![Literature Fingerprints](assets/fingerprints.png)

[Literature Fingerprints](https://kops.uni-konstanz.de/bitstream/handle/123456789/5492/Literature_Fingerprinting.pdf)

Sentence Length

---
<br/><br/>
![Literature Fingerprints](assets/fingerprints3.png)


Hapax Legomena

_(Words that occur only once in the document)_
---

![word tree](assets/wordtree.png)
[Word Tree](https://www.jasondavies.com/wordtree/?source=alice-in-wonderland.txt&prefix=cried)

---

![origin of species](assets/origin.png)
[The Origin of Species](http://fathom.info/traces)


---
class:middle
# Time
---

<br/>
<br/>
![how the internet talks](assets/internet_talks.png)
<br/>
<br/>
[How the Internet Talks](http://projects.fivethirtyeight.com/reddit-ngram/?keyword=lol.win.omg.cute.fail.wtf&start=20071015&end=20150831&smoothing=10)

<!-- ---
![history flow](assets/history_flow.png)
[History Flow](http://www.bewitched.com/historyflow.html) -->

---

![Notabilia](assets/notabilia.png)
[Notabilia](http://notabilia.net/)


---
class:middle
# Collections
---

![pop sci](assets/popsci.png)
[Popular Science Archive Explorer](http://www.popsci.com/content/wordfrequency#Elephant)

---

![Dissertation browser](assets/dissertation.png)
[Dissertation Browser](http://www-nlp.stanford.edu/projects/dissertations/browser.html)

---
class:center,middle
# Artistic Representations

---

![lit org](assets/lit_org.jpg)
[Literary Organism](http://www.stefanieposavec.co.uk/personal/#/writing-without-words/)

---

![lit org](assets/lit_org2.jpg)
[Literary Organism](http://www.stefanieposavec.co.uk/personal/#/writing-without-words/)

---

![sentence drawings](assets/sentence.jpg)
[Sentence Drawings](http://www.stefanieposavec.co.uk/personal/#/writing-without-words/)

---

![code sentence drawings](assets/code_sentence.png)
[Sentence Drawings (Code Based)](http://vallandingham.me/sentence_drawings/#gatsby)

---
<br/>
<br/>
![punc](assets/punc.jpg)

[Between the Words](http://www.c82.net/work/?id=347)

---

![rep](assets/rep2.png)

[Visualizing Repetition](http://projects.chass.utoronto.ca/chwp/CHC2007/Ruecker_etal/Ruecker_etal.htm)

---


# And Many More

![collection](assets/collection.png)
[Academic Text Vis Collection](http://textvis.lnu.se/)

---
class:middle,center

## http://vallandingham.me/textvis-talk/

---

</textarea>
  <script src="vendor/remark.min.js" type="text/javascript"></script>
  <script type="text/javascript">
    var slideshow = remark.create();
  </script>
  <script src="vendor/underscore.js" type="text/javascript"></script>
  <script src="vendor/d3.js" type="text/javascript"></script>


  <script>
  var links = document.links;

  for (var i = 0, linksLength = links.length; i < linksLength; i++) {
    if (links[i].hostname != window.location.hostname) {
      links[i].target = '_blank';
    }
  }
  </script>
</body>
